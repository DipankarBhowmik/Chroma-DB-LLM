{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "185f1717-3cb5-4618-b07c-3f5555bb94b3",
   "metadata": {},
   "source": [
    "# Enhancing Medical Report Findings with Retrieval-Augmented Generation (RAG): Integrating LLM Models and Chroma DB using the LangChain framework for searchable data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80c4b2d-61d5-4861-81d3-32c5d599923b",
   "metadata": {},
   "source": [
    "### Installing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "697b86b7-0892-4c70-b75a-2aa3d0842f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\bhowm\\appdata\\roaming\\python\\python312\\site-packages (3.0.1)\n",
      "Requirement already satisfied: chromadb==0.4.0 in c:\\users\\bhowm\\appdata\\roaming\\python\\python312\\site-packages (0.4.0)\n",
      "Collecting langchain==0.2.0\n",
      "  Using cached langchain-0.2.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas>=1.3 in c:\\users\\bhowm\\appdata\\roaming\\python\\python312\\site-packages (from chromadb==0.4.0) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.28 in c:\\users\\bhowm\\.conda\\envs\\new1\\lib\\site-packages (from chromadb==0.4.0) (2.32.3)\n",
      "Collecting pydantic<2.0,>=1.9 (from chromadb==0.4.0)\n",
      "  Using cached pydantic-1.10.19-cp312-cp312-win_amd64.whl.metadata (153 kB)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.1 in c:\\users\\bhowm\\appdata\\roaming\\python\\python312\\site-packages (from chromadb==0.4.0) (0.7.1)\n",
      "Requirement already satisfied: fastapi<0.100.0,>=0.95.2 in c:\\users\\bhowm\\appdata\\roaming\\python\\python312\\site-packages (from chromadb==0.4.0) (0.99.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\bhowm\\appdata\\roaming\\python\\python312\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.0) (0.34.0)\n",
      "Collecting numpy>=1.21.6 (from chromadb==0.4.0)\n",
      "  Downloading numpy-2.2.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\bhowm\\appdata\\roaming\\python\\python312\\site-packages (from chromadb==0.4.0) (3.7.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\bhowm\\.conda\\envs\\new1\\lib\\site-packages (from chromadb==0.4.0) (4.12.2)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in c:\\users\\bhowm\\appdata\\roaming\\python\\python312\\site-packages (from chromadb==0.4.0) (3.5.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\bhowm\\appdata\\roaming\\python\\python312\\site-packages (from chromadb==0.4.0) (1.20.1)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb==0.4.0)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\bhowm\\appdata\\roaming\\python\\python312\\site-packages (from chromadb==0.4.0) (0.48.9)\n",
      "Collecting tqdm>=4.65.0 (from chromadb==0.4.0)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\bhowm\\.conda\\envs\\new1\\lib\\site-packages (from chromadb==0.4.0) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\bhowm\\appdata\\roaming\\python\\python312\\site-packages (from chromadb==0.4.0) (6.4.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\bhowm\\.conda\\envs\\new1\\lib\\site-packages (from langchain==0.2.0) (6.0.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain==0.2.0)\n",
      "  Using cached SQLAlchemy-2.0.36-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain==0.2.0)\n",
      "  Using cached aiohttp-3.11.11-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.2.0)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain-core<0.3.0,>=0.2.0 (from langchain==0.2.0)\n",
      "  Using cached langchain_core-0.2.43-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain==0.2.0)\n",
      "  Using cached langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.2.0)\n",
      "  Using cached langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy>=1.21.6 (from chromadb==0.4.0)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain==0.2.0)\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.3.13-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.12-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.11-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain==0.2.0)\n",
      "  Using cached SQLAlchemy-2.0.35-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached langchain_community-0.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Using cached langchain_community-0.3.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Using cached langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Using cached langchain_community-0.2.19-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Using cached langchain_community-0.2.18-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Using cached langchain_community-0.2.17-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Using cached langchain_community-0.2.16-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Using cached langchain_community-0.2.15-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Using cached langchain_community-0.2.13-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Using cached langchain_community-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Using cached langchain_community-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Using cached langchain_community-0.2.10-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Using cached langchain_community-0.2.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_community-0.2.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_community-0.2.6-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_community-0.2.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_community-0.2.4-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.5.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.6.0-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.15.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Downloading pillow-11.1.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\bhowm\\.conda\\envs\\new1\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (24.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0)\n",
      "  Using cached frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0)\n",
      "  Using cached multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0)\n",
      "  Using cached propcache-0.2.1-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0)\n",
      "  Using cached yarl-1.18.3-cp312-cp312-win_amd64.whl.metadata (71 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.2.0)\n",
      "  Downloading marshmallow-3.24.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.2.0)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\users\\bhowm\\appdata\\roaming\\python\\python312\\site-packages (from fastapi<0.100.0,>=0.95.2->chromadb==0.4.0) (0.27.0)\n",
      "Collecting filelock (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\bhowm\\.conda\\envs\\new1\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.0->langchain==0.2.0)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-core<0.3.0,>=0.2.0 (from langchain==0.2.0)\n",
      "  Using cached langchain_core-0.2.42-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Using cached langchain_core-0.2.41-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Using cached langchain_core-0.2.40-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Using cached langchain_core-0.2.39-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Using cached langchain_core-0.2.38-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Using cached langchain_core-0.2.37-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Using cached langchain_core-0.2.36-py3-none-any.whl.metadata (6.2 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached langchain_core-0.2.35-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Using cached langchain_core-0.2.34-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Using cached langchain_core-0.2.33-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Using cached langchain_core-0.2.32-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Using cached langchain_core-0.2.30-py3-none-any.whl.metadata (6.2 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached langchain_core-0.2.29-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Using cached langchain_core-0.2.28-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Using cached langchain_core-0.2.27-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Using cached langchain_core-0.2.26-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Using cached langchain_core-0.2.25-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Using cached langchain_core-0.2.24-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Using cached langchain_core-0.2.23-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Using cached langchain_core-0.2.22-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.2.21-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.2.20-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.2.19-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.2.18-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.2.17-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.2.15-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.2.13-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.2.12-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.2.11-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.2.10-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.2.9-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.2.8-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain==0.2.0)\n",
      "  Using cached langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "  Using cached langchain_text_splitters-0.2.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\bhowm\\.conda\\envs\\new1\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (0.27.0)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.2.0)\n",
      "  Downloading orjson-3.10.13-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "INFO: pip is looking at multiple versions of langsmith to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.2.0)\n",
      "  Using cached langsmith-0.1.146-py3-none-any.whl.metadata (14 kB)\n",
      "  Using cached langsmith-0.1.145-py3-none-any.whl.metadata (14 kB)\n",
      "  Using cached langsmith-0.1.144-py3-none-any.whl.metadata (14 kB)\n",
      "  Using cached langsmith-0.1.143-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.142-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.139-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.138-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: pip is still looking at multiple versions of langsmith to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached langsmith-0.1.137-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.134-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.133-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.132-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.131-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached langsmith-0.1.129-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.128-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.127-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.126-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.125-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.124-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.123-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.122-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.121-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.120-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.119-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.118-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.117-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.116-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.115-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.114-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.113-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.112-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.111-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.110-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.109-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.108-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.107-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.106-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.105-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.104-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.103-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.102-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.101-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.99-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.98-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.97-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.96-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.95-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.94-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.93-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.92-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.91-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.90-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.89-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.88-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.87-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.86-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.85-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.84-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.83-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.82-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langsmith-0.1.81-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\bhowm\\appdata\\roaming\\python\\python312\\site-packages (from onnxruntime>=1.14.1->chromadb==0.4.0) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\bhowm\\appdata\\roaming\\python\\python312\\site-packages (from onnxruntime>=1.14.1->chromadb==0.4.0) (24.3.25)\n",
      "Requirement already satisfied: protobuf in c:\\users\\bhowm\\appdata\\roaming\\python\\python312\\site-packages (from onnxruntime>=1.14.1->chromadb==0.4.0) (5.29.2)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb==0.4.0)\n",
      "  Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\bhowm\\.conda\\envs\\new1\\lib\\site-packages (from pandas>=1.3->chromadb==0.4.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bhowm\\.conda\\envs\\new1\\lib\\site-packages (from pandas>=1.3->chromadb==0.4.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bhowm\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.3->chromadb==0.4.0) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bhowm\\.conda\\envs\\new1\\lib\\site-packages (from posthog>=2.4.0->chromadb==0.4.0) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\bhowm\\appdata\\roaming\\python\\python312\\site-packages (from posthog>=2.4.0->chromadb==0.4.0) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\bhowm\\appdata\\roaming\\python\\python312\\site-packages (from posthog>=2.4.0->chromadb==0.4.0) (2.2.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\bhowm\\.conda\\envs\\new1\\lib\\site-packages (from pulsar-client>=3.1.0->chromadb==0.4.0) (2024.12.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bhowm\\.conda\\envs\\new1\\lib\\site-packages (from requests>=2.28->chromadb==0.4.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bhowm\\.conda\\envs\\new1\\lib\\site-packages (from requests>=2.28->chromadb==0.4.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bhowm\\.conda\\envs\\new1\\lib\\site-packages (from requests>=2.28->chromadb==0.4.0) (2.2.3)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain==0.2.0)\n",
      "  Using cached greenlet-3.1.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bhowm\\.conda\\envs\\new1\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bhowm\\.conda\\envs\\new1\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb==0.4.0)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb==0.4.0)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\bhowm\\.conda\\envs\\new1\\lib\\site-packages (from tqdm>=4.65.0->chromadb==0.4.0) (0.4.6)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.5.0-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\bhowm\\appdata\\roaming\\python\\python312\\site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb==0.4.0) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\bhowm\\.conda\\envs\\new1\\lib\\site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb==0.4.0) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\bhowm\\appdata\\roaming\\python\\python312\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.0) (0.6.4)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.4.0)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\bhowm\\appdata\\roaming\\python\\python312\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.0) (1.0.3)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\bhowm\\appdata\\roaming\\python\\python312\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.0) (14.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain==0.2.0)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\bhowm\\.conda\\envs\\new1\\lib\\site-packages (from starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb==0.4.0) (4.6.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.2.0)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\bhowm\\appdata\\roaming\\python\\python312\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.0) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bhowm\\.conda\\envs\\new1\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\bhowm\\.conda\\envs\\new1\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb==0.4.0) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\bhowm\\appdata\\roaming\\python\\python312\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.0) (3.5.4)\n",
      "Using cached langchain-0.2.0-py3-none-any.whl (973 kB)\n",
      "Using cached langchain_community-0.2.4-py3-none-any.whl (2.2 MB)\n",
      "Using cached sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "Using cached aiohttp-3.11.11-cp312-cp312-win_amd64.whl (437 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "Using cached langchain_core-0.2.8-py3-none-any.whl (315 kB)\n",
      "Using cached pydantic-1.10.19-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Using cached langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\n",
      "Using cached langsmith-0.1.81-py3-none-any.whl (127 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Using cached SQLAlchemy-2.0.36-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "Using cached tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached torch-2.5.1-cp312-cp312-win_amd64.whl (203.0 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
      "Downloading pillow-11.1.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 2.1/2.6 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 4.0 MB/s eta 0:00:00\n",
      "Using cached scikit_learn-1.6.0-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "Downloading scipy-1.15.0-cp312-cp312-win_amd64.whl (43.6 MB)\n",
      "   ---------------------------------------- 0.0/43.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.6/43.6 MB 7.0 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 2.6/43.6 MB 6.6 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 2.6/43.6 MB 6.6 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 2.6/43.6 MB 6.6 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 2.6/43.6 MB 6.6 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 3.1/43.6 MB 2.5 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 3.7/43.6 MB 2.5 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 3.9/43.6 MB 2.4 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 3.9/43.6 MB 2.4 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 4.5/43.6 MB 2.1 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 4.7/43.6 MB 2.1 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 5.0/43.6 MB 1.9 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 5.0/43.6 MB 1.9 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 5.2/43.6 MB 1.7 MB/s eta 0:00:23\n",
      "   ---- ----------------------------------- 5.2/43.6 MB 1.7 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 5.5/43.6 MB 1.6 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 5.8/43.6 MB 1.6 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 5.8/43.6 MB 1.6 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 5.8/43.6 MB 1.6 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 6.0/43.6 MB 1.4 MB/s eta 0:00:27\n",
      "   ----- ---------------------------------- 6.0/43.6 MB 1.4 MB/s eta 0:00:27\n",
      "   ----- ---------------------------------- 6.0/43.6 MB 1.4 MB/s eta 0:00:27\n",
      "   ----- ---------------------------------- 6.0/43.6 MB 1.4 MB/s eta 0:00:27\n",
      "   ----- ---------------------------------- 6.3/43.6 MB 1.2 MB/s eta 0:00:31\n",
      "   ------ --------------------------------- 6.6/43.6 MB 1.3 MB/s eta 0:00:30\n",
      "   ------ --------------------------------- 7.3/43.6 MB 1.3 MB/s eta 0:00:28\n",
      "   ------- -------------------------------- 8.4/43.6 MB 1.5 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 9.4/43.6 MB 1.6 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 10.5/43.6 MB 1.7 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 11.5/43.6 MB 1.8 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 12.6/43.6 MB 1.9 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 13.4/43.6 MB 2.0 MB/s eta 0:00:16\n",
      "   ------------- -------------------------- 14.7/43.6 MB 2.1 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 15.7/43.6 MB 2.2 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 16.5/43.6 MB 2.3 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 17.6/43.6 MB 2.3 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 18.9/43.6 MB 2.4 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 19.4/43.6 MB 2.4 MB/s eta 0:00:10\n",
      "   ------------------ --------------------- 20.4/43.6 MB 2.5 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 21.8/43.6 MB 2.6 MB/s eta 0:00:09\n",
      "   -------------------- ------------------- 22.5/43.6 MB 2.6 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 23.6/43.6 MB 2.7 MB/s eta 0:00:08\n",
      "   ---------------------- ----------------- 24.6/43.6 MB 2.7 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 26.0/43.6 MB 2.8 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 26.7/43.6 MB 2.8 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 27.5/43.6 MB 2.9 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 28.3/43.6 MB 2.9 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 29.6/43.6 MB 3.0 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 30.4/43.6 MB 3.0 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 30.9/43.6 MB 3.0 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 32.2/43.6 MB 3.0 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 33.3/43.6 MB 3.1 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 34.6/43.6 MB 3.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 35.7/43.6 MB 3.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 36.4/43.6 MB 3.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 37.2/43.6 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 38.5/43.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 39.8/43.6 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 40.4/43.6 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.4/43.6 MB 3.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 42.5/43.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.5/43.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.5/43.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.5/43.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 43.6/43.6 MB 3.2 MB/s eta 0:00:00\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached frozenlist-1.5.0-cp312-cp312-win_amd64.whl (51 kB)\n",
      "Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Using cached greenlet-3.1.1-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading marshmallow-3.24.1-py3-none-any.whl (49 kB)\n",
      "Using cached multidict-6.1.0-cp312-cp312-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.13-cp312-cp312-win_amd64.whl (135 kB)\n",
      "Using cached propcache-0.2.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Downloading safetensors-0.5.0-cp38-abi3-win_amd64.whl (303 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.18.3-cp312-cp312-win_amd64.whl (90 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mpmath, tqdm, threadpoolctl, tenacity, sympy, safetensors, regex, python-dotenv, pydantic, propcache, Pillow, orjson, numpy, networkx, mypy-extensions, multidict, marshmallow, jsonpointer, joblib, greenlet, fsspec, frozenlist, filelock, aiohappyeyeballs, yarl, typing-inspect, torch, SQLAlchemy, scipy, langsmith, jsonpatch, huggingface-hub, aiosignal, tokenizers, scikit-learn, langchain-core, dataclasses-json, aiohttp, transformers, langchain-text-splitters, sentence-transformers, langchain, langchain-community\n",
      "Successfully installed Pillow-11.1.0 SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 dataclasses-json-0.6.7 filelock-3.16.1 frozenlist-1.5.0 fsspec-2024.12.0 greenlet-3.1.1 huggingface-hub-0.27.1 joblib-1.4.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.0 langchain-community-0.2.4 langchain-core-0.2.8 langchain-text-splitters-0.2.1 langsmith-0.1.81 marshmallow-3.24.1 mpmath-1.3.0 multidict-6.1.0 mypy-extensions-1.0.0 networkx-3.4.2 numpy-1.26.4 orjson-3.10.13 propcache-0.2.1 pydantic-1.10.19 python-dotenv-1.0.1 regex-2024.11.6 safetensors-0.5.0 scikit-learn-1.6.0 scipy-1.15.0 sentence-transformers-3.3.1 sympy-1.13.1 tenacity-8.5.0 threadpoolctl-3.5.0 tokenizers-0.21.0 torch-2.5.1 tqdm-4.67.1 transformers-4.47.1 typing-inspect-0.9.0 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install \"PyPDF2\" \"chromadb==0.4.0\" \"langchain==0.2.0\" \"langchain-community\" \"sentence-transformers\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06946fa-0edf-4c84-a502-5805ee7da305",
   "metadata": {},
   "source": [
    "### Reading PDF reports and remove sensitive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eafb9c74-bc21-4c75-b78f-c0b7e5fa186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "def read_pdf(file_path):\n",
    "    # Initialize the reader for the PDF file\n",
    "    \n",
    "    reader = PdfReader(file_path)\n",
    "    \n",
    "    # Extract text from each page and store it in a variable\n",
    "    pdf_text = \"\"\n",
    "    for page in reader.pages:\n",
    "        pdf_text += page.extract_text() + \"\\n\"  # Adding a newline for separation between pages\n",
    "  \n",
    "    text = pdf_text.replace(\"\\n\", \" \")\n",
    "    \n",
    "    return text\n",
    "    #return page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee0b91ca-5ed2-4177-a2b1-94320a6c151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_sensitive(text):\n",
    "    text = re.sub(r\"Patient\\s+Name\\s+:\\s+.*?\\s+(?=Patient\\s+ID)\", \"\", text)#removing patient name\n",
    "    text = re.sub(r\"Referring\\s+Physician\\s+.*?\\s+Report\", \"Report\", text)\n",
    "    text = re.sub(r\"Dr [A-Za-z\\s]+MD\\s*|Reg No:\\s*\\d+\", \"\", text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fe0c51-a212-403e-b1c8-34f042a87249",
   "metadata": {},
   "source": [
    "### Creating field for json and removing other sensitive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0683046c-7067-48a9-aed3-befa99815cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "def text_json(extracted_data):\n",
    "# Regex patterns to extract fields\n",
    "    patterns = {\n",
    "        \"Patient ID\": r\"Patient\\s+ID\\s*:\\s*(\\S+)\",\n",
    "        \"Date\": r\"Report\\s+Date\\s+/ Time\\s+:\\s+(\\d{1,2}\\s+\\w+\\s+\\d{4})\",\n",
    "        \"Time\": r\"(\\d{2}:\\d{2}:\\d{2})\",\n",
    "        \"Patient age\": r\"Patient\\s+age\\s+/\\s+Sex\\s+:\\s+(\\d{3}Y)\",\n",
    "        \"Sex\": r\"Sex\\s*:\\s*\\d{3}[A-Za-z]*\\s*/\\s*(\\w)\",\n",
    "        \"TECHNIQUE\": r\"TECHNIQUE\\s*:\\s*(.*?)\\s*FINDINGS\",\n",
    "        \"FINDINGS\": r\"FINDINGS\\s*:\\s*(.*?)\\s*IMPRESSION\",\n",
    "        \"IMPRESSION\": r\"IMPRESSION\\s*:\\s*(.*)\"\n",
    "    }\n",
    "    \n",
    "    # Extract fields using regex\n",
    "    data = {}\n",
    "    for key, pattern in patterns.items():\n",
    "        match = re.search(pattern, extracted_data, re.DOTALL)\n",
    "        if match:\n",
    "            data[key] = match.group(1).strip()\n",
    "    \n",
    "    # removes the unwanted portion from the \"FINDINGS\" and \"IMPRESSION\" field while keeping the rest of the content intact.\n",
    "    try:\n",
    "        findings = data[\"FINDINGS\"]\n",
    "        impression = data[\"IMPRESSION\"]\n",
    "        updated_findings = re.sub(r\"Patient\\s+ID\\s*:\\s*(\\S+).*Report\\s+Date\\s+/ Time\\s+:\\s+(\\d{1,2}\\s+\\w+\\s+\\d{4})\\s*(\\S+)\", \"\", findings).strip()\n",
    "        updated_impression = re.sub(r\"Patient\\s+ID\\s*:\\s*(\\S+).*Report\\s+Date\\s+/ Time\\s+:\\s+(\\d{1,2}\\s+\\w+\\s+\\d{4})\\s*(\\S+)\", \"\", impression).strip()\n",
    "\n",
    "        # Update the Data\n",
    "        data[\"FINDINGS\"] = updated_findings\n",
    "        data[\"IMPRESSION\"] = updated_impression\n",
    "    except:\n",
    "        print(\"no unwanted found\")\n",
    "    # Update the JSON\n",
    "    json_data = json.dumps(data, indent=4)\n",
    "    \n",
    "    return json_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6489beb2-af33-4b44-b029-37192d67202e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Patient ID\": \"MR0000444444\",\n",
      "    \"Date\": \"20 April  2020\",\n",
      "    \"Time\": \"10:16:04\",\n",
      "    \"Patient age\": \"075Y\",\n",
      "    \"Sex\": \"M\",\n",
      "    \"TECHNIQUE\": \"T2 FSE Axials  / Sagittals  & Coronals.   T1 &T2  FLAIR  Axials.  DWI,  GRE  Axials.    3D TOF  MR Angiography  of Intracranial  Arteries.\",\n",
      "    \"FINDINGS\": \"Large wedge shaped lesion with restricted diffusion low ADC values and hyperintensities  in T2 & FLAIR images noted involving capsuloganglionic region, parietal lobe, adjacent  frontal insular cortex, temporal lobe in right side.   Focal FLAIR hyperintensities without restricted diffusion in bilateral posterior  periventricular wh ite matter, left corona radiata and centrum semiovale.   Curvilinear  blooming  SWI hypointensities  in distal  right  MCA.   Cerebellum, 4th ventricle, brain stem & CP angle regions are within normal limits.  Sella, suprasellar & parasellar areas are normal.   The ex tracerebral spaces and supratentorial ventricular system are normal.  Rest of the cerebral parenchyma is normal is normal.   Midline structures and corpus callosum are normal.  No haemorrhagic pathology.   No extraaxial  collection  seen.   MR Angiography  shows :  Hypoplastic  left vertebral  artery.   Distal  left vertebral  artery  not well visualised.   Focal  mild stenosis  in basilar  artery  in P1 segment  of left PCA.        Non visualisation  of distal  2/3rds  of right  MCA  and distal  right  MCA  branches.   Bilateral intracranial internal carotid arteries, anterior & left middle cerebral arteries  and their branches are normal in caliber/flow signal.   Otherwise basilar artery, bilateral posterior cerebral, superior cerebellar and anterior  inferior cerebellar arteries are normal in ca liber and course.   Right vertebral artery is normal in calibre and flow signal.  No aneurysm / AVM seen.\",\n",
      "    \"IMPRESSION\": \"* Large acute non haemorrhagic infract in right MCA territory involving  capsuloganglionic region,  parietal lobe, adjacent frontal insular corte x,  temporal lobe in right side.   * Curvilinear thrombus in distal right MCA causing occlusion and non  visualisation of distal right MCA and right MCA distal branches.   * Chronic ischemic demylenation in bilateral posterior periventricular white  matter, left coro na radiata and centrum semiovale.   * Hyoplastic  left vertebral  artery.  Distal  left vertebral  artery  not well visualised   - ? Due to occlusion  / ? Very  slow  flow status.   * Focal  mild  stenosis  in basilar  artery  in P1 segment  of left PCA.       Consultant Radiologist\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Define the file path to the PDF file named \"MO.pdf\" in the current working directory\n",
    "file_path = r\"Data/MO.pdf\"  # The 'r' prefix indicates a raw string to handle any special characters in the path\n",
    "\n",
    "# Read the PDF file and extract its content as text\n",
    "print(\n",
    "    # Remove sensitive information like patient name, physician name, etc.\n",
    "    text_json(\n",
    "        remove_sensitive(\n",
    "            read_pdf(file_path)  # Read PDF and extract text content\n",
    "        )\n",
    "    )\n",
    ")\n",
    "# Convert the sanitized text to a structured JSON format and print it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0dc7e8-0e28-4e1e-814b-915ab8f613d8",
   "metadata": {},
   "source": [
    "### Processing multiple pdf file for chromadb format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f63da21-07cb-4dab-b8ad-2bbe32cf0549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/MO.pdf\n",
      "Data/RA.pdf\n",
      "Data/VA.pdf\n"
     ]
    }
   ],
   "source": [
    "# Process all PDF files in the folder\n",
    "import os\n",
    "folder_path = r\"Data/\"\n",
    "all_data = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(folder_path, filename)\n",
    "        print(pdf_path)\n",
    "        extracted_data = read_pdf(pdf_path)\n",
    "        remove_sensitive_data = remove_sensitive(extracted_data)\n",
    "        extracted_json = text_json(remove_sensitive_data)\n",
    "        ## Parse the JSON strings into dictionaries and append to the list\n",
    "        all_data.append(json.loads(extracted_json))\n",
    "#print(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09459700-87bc-48bf-8a80-c4076b43f45a",
   "metadata": {},
   "source": [
    "### Converting JSON to ChromaDB format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f0a90c7-523e-43d7-810d-a5cb13f95926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "documents = [\n",
    "    Document(page_content=f\"{item['Patient ID']} {item['Patient age']} {item['Sex']} {item['TECHNIQUE']} {item['FINDINGS']} {item['IMPRESSION']}\", metadata={})\n",
    "    for item in all_data\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6493071-8e88-4121-a957-905ed5d3b433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Content: MR0000444444 075Y M T2 FSE Axials  / Sagittals  & Coronals.   T1 &T2  FLAIR  Axials.  DWI,  GRE  Axials.    3D TOF  MR Angiography  of Intracranial  Arteries. Large wedge shaped lesion with restricted diffusion low ADC values and hyperintensities  in T2 & FLAIR images noted involving capsuloganglionic region, parietal lobe, adjacent  frontal insular cortex, temporal lobe in right side.   Focal FLAIR hyperintensities without restricted diffusion in bilateral posterior  periventricular wh ite matter, left corona radiata and centrum semiovale.   Curvilinear  blooming  SWI hypointensities  in distal  right  MCA.   Cerebellum, 4th ventricle, brain stem & CP angle regions are within normal limits.  Sella, suprasellar & parasellar areas are normal.   The ex tracerebral spaces and supratentorial ventricular system are normal.  Rest of the cerebral parenchyma is normal is normal.   Midline structures and corpus callosum are normal.  No haemorrhagic pathology.   No extraaxial  collection  seen.   MR Angiography  shows :  Hypoplastic  left vertebral  artery.   Distal  left vertebral  artery  not well visualised.   Focal  mild stenosis  in basilar  artery  in P1 segment  of left PCA.        Non visualisation  of distal  2/3rds  of right  MCA  and distal  right  MCA  branches.   Bilateral intracranial internal carotid arteries, anterior & left middle cerebral arteries  and their branches are normal in caliber/flow signal.   Otherwise basilar artery, bilateral posterior cerebral, superior cerebellar and anterior  inferior cerebellar arteries are normal in ca liber and course.   Right vertebral artery is normal in calibre and flow signal.  No aneurysm / AVM seen. * Large acute non haemorrhagic infract in right MCA territory involving  capsuloganglionic region,  parietal lobe, adjacent frontal insular corte x,  temporal lobe in right side.   * Curvilinear thrombus in distal right MCA causing occlusion and non  visualisation of distal right MCA and right MCA distal branches.   * Chronic ischemic demylenation in bilateral posterior periventricular white  matter, left coro na radiata and centrum semiovale.   * Hyoplastic  left vertebral  artery.  Distal  left vertebral  artery  not well visualised   - ? Due to occlusion  / ? Very  slow  flow status.   * Focal  mild  stenosis  in basilar  artery  in P1 segment  of left PCA.       Consultant Radiologist, Metadata: {}\n",
      "Page Content: MR0000222222 062Y M T2 FSE Axials  / Sagittals  & Coronals.   T1 &T2  FLAIR  Axials.  DWI,  GRE  Axials.   3D TOF  MR Angiography  of Intracranial  Arteries. Wedge shaped lesion showing restricted diffusion, low ADC values and slightly  hyperintense on FLAIR images involving right side parietal lobe, insular cortex, adjacent  frontal lobe and capsuloganglionic region.   Small lesions in parafalcine inferior both occipital lobes is hypointense on T1,  predominantly hypointense with adjacent hyperintensities on FLAIR and hyperintense on  T2 WI.   Lacunar FLAIR hyperintensities without restricted diffusion in right side anterior  corona  radiata.   Mega  cisterna  magna  seen - Normal  variant.   Cerebellum, 4th ventricle, brain stem & CP angle regions are within normal limits.  Sella, suprasellar & parasellar areas are normal.   The extracerebral spaces and supratentorial ventricular system are normal.  Rest of the cerebral parenchyma is normal.   Midline  structures  and corpus  callosum  are normal.   No haemorrhagic pathology. No extraaxial collection seen.  MR Angiography shows : (Patient is not cooperative)   Distal right MCA branches are not well visualized.   Small  stenotic  segment  in distal  left MCA.   Mild  stenosis  seen in cavernous  and infrapetrous  parts  of right  ICA.         Fetal  type of A1 segment  of right  ACA  -- Normal  varient.   Hypoplastic  right  vertebral  artery.   Left internal  carotid,  right  MCA  and rest of the left MCA  are normal  in caliber.   Bilateral intracranial anterior cerebral arteries and their branches are normal in caliber/flow  signal.   The basilar artery, bilateral posterior cerebral, superior cerebellar and anterior inferior  cerebellar arteries are norm al in caliber and course.   Left vertebral artery is normal in calibre and flow signal.  No aneurysm / AVM seen. * Non hemorrhagic hyperacute on acute infarct in right MCA territory,  involving right side parietal lobe, insular cortex, adjacent frontal lobe and  capsuloganglionic region.   * Small  lesions  of gliosis  / old infarcts  in parafalcine  inferior  both  occipital  lobes .  * Focal chronic infarct with residual chronic ischemic demyelination in right  side anterior corona radiata.   * Distal right MCA branches are not well visualized, possible due to slow flow  status / occlusion.   * Small  stenotic  segment  in distal  left MCA.   * Mild  stenosis  in cavernous  and infrapetrous  parts  of right  ICA.   * Hypoplastic  right  vertebral  artery.       Consultant Radiologist, Metadata: {}\n",
      "Page Content: IP0000111111 067Y M T1, T2 & FLAIR  Axials,T2  Saggitals  / Coronals.  DWI  Axials.   Clinical  details  : S/p CABG  for CAD. Evidence of multiple lacunar &  tiny sized lesions with restricted diffusion and low ADC  values are hyperintense on FLAIR images noted in both cerebellar hemispheres, occipital  lobes and parietooccipital regions (including right side of splenium of corpus callosum),  left posterior periv entricular white matter, left posterior temporal lobe, left frontal corona  radiata & centrum semiovale, left high parietal cortex and right side corona radiata,  centrum semiovale and high parietal cortex and as a tiny lesion in lateral wall of the   frontal horn of right lateral ventricle.   Rest of the cerebral  parenchyma  is normal.   Both  lateral  and third  ventricles  are mildly  dilated.   Bilateral sylvian fissures, cerebral sulcal spaces and basi cisternal spaces are widened.  Pons, medulla and midbrain are normal.   No shift of midline  structures.   Pituitary gland, infundibulum and optic chiasm are normal.  No hemorrhagic pathology.   Screening  MR Angio  : Normal  major  intracranial  arteries.    :04 * Multiple tiny & lacunar sized non hemorrhagic acute infarcts in bilateral  cerebellar hemispheres, occipital lobes &  parietooccipital regions (including  right side of splenium of corpus callosum), left sided posterior periventricular  white matter, posterior temporal lobe, frontal corona radiata, centrum  semiovale, high parietal cortex and right sided corona radiata, cen trum  semiovale, high parietal cortex and lateral wall of the frontal horn of right  lateral ventricle -- Embolic etiology.   * Age related  mild  cerebral  atrophy.       For clinical  correlation.         Consultant Radiologist, Metadata: {}\n"
     ]
    }
   ],
   "source": [
    "# Verify the result\n",
    "for doc in documents:\n",
    "    print(f\"Page Content: {doc.page_content}, Metadata: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe219a7-37df-4a70-849f-a242ca30e457",
   "metadata": {},
   "source": [
    "### Creating chunks from document from chromaDB (vector database)\n",
    "### Using all-MiniLM-L6-v2 embedings\n",
    "### Saving the data into chromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "675f842c-9e22-42b4-bab0-5c743f8597e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data has been successfully inserted into ChromaDB!\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# -------------------------------\n",
    "# Split Data into Chunks (Optional for Large Content)\n",
    "# -------------------------------\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "split_documents = text_splitter.split_documents(documents)\n",
    "\n",
    "# -------------------------------\n",
    "# Use Hugging Face Embeddings (all-MiniLM-L6-v2)\n",
    "# -------------------------------\n",
    "embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "\n",
    "# -------------------------------\n",
    "# Store Embeddings in ChromaDB\n",
    "# -------------------------------\n",
    "chroma_db4 = Chroma.from_documents(split_documents, embeddings, persist_directory=\"./chroma_sample_db\")\n",
    "\n",
    "# Save embeddings to the ChromaDB directory\n",
    "chroma_db4.persist()\n",
    "print(\"✅ Data has been successfully inserted into ChromaDB!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cc95e354-2bec-49ec-a0cd-21c7b1da6693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ") model_name='sentence-transformers/all-MiniLM-L6-v2' cache_folder=None model_kwargs={} encode_kwargs={} multi_process=False show_progress=False\n"
     ]
    }
   ],
   "source": [
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d5277d-1485-4333-8104-b9ef1b478080",
   "metadata": {},
   "source": [
    "### Test Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8224eb14-2b06-4452-8af8-5f9388c8ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_queries(queries, k):\n",
    "    # Create a retriever instance from the Chroma database to retrieve relevant documents\n",
    "    retriever = chroma_db4.as_retriever()\n",
    "    # Loop through each query in the test_queries list\n",
    "    for query in queries:\n",
    "        # Retrieve the top k most relevant documents for the current query\n",
    "        results = retriever.get_relevant_documents(query, k=k)\n",
    "        \n",
    "        # Print the current query being tested\n",
    "        print(f\"🔍 Query: {query}\")\n",
    "        \n",
    "        # Loop through the top k results and display their content\n",
    "        for i, doc in enumerate(results[:k]):  # Limit to top k results\n",
    "            print(f\"💡 Result {i+1}: {doc.page_content}\")\n",
    "        \n",
    "        # Print a separator line for better readability between results\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ed8b6a57-8bac-4e64-8d82-b892e198e84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Query: Patient is not cooperative\n",
      "💡 Result 1: are normal.  Rest of the cerebral parenchyma is normal.   Midline  structures  and corpus  callosum  are normal.   No haemorrhagic pathology. No extraaxial collection seen.  MR Angiography shows : (Patient is not cooperative)   Distal right MCA branches are not well visualized.   Small  stenotic  segment  in distal  left MCA.   Mild  stenosis  seen in cavernous  and infrapetrous  parts  of right  ICA.         Fetal  type of A1 segment  of right  ACA  -- Normal  varient.   Hypoplastic  right\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define a list of test queries to be processed\n",
    "queries = [\"Patient is not cooperative\"]\n",
    "k = 1\n",
    "retrieve_queries(queries, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "01331cbb-866c-4d68-9465-a7c2190d04ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Query: Patient is not cooperative\n",
      "💡 Result 1: are normal.  Rest of the cerebral parenchyma is normal.   Midline  structures  and corpus  callosum  are normal.   No haemorrhagic pathology. No extraaxial collection seen.  MR Angiography shows : (Patient is not cooperative)   Distal right MCA branches are not well visualized.   Small  stenotic  segment  in distal  left MCA.   Mild  stenosis  seen in cavernous  and infrapetrous  parts  of right  ICA.         Fetal  type of A1 segment  of right  ACA  -- Normal  varient.   Hypoplastic  right\n",
      "💡 Result 2: are normal.  Rest of the cerebral parenchyma is normal.   Midline  structures  and corpus  callosum  are normal.   No haemorrhagic pathology. No extraaxial collection seen.  MR Angiography shows : (Patient is not cooperative)   Distal right MCA branches are not well visualized.   Small  stenotic  segment  in distal  left MCA.   Mild  stenosis  seen in cavernous  and infrapetrous  parts  of right  ICA.         Fetal  type of A1 segment  of right  ACA  -- Normal  varient.   Hypoplastic  right\n",
      "--------------------------------------------------\n",
      "🔍 Query: including right side of splenium of corpus callosum\n",
      "💡 Result 1: IP0000111111 067Y M T1, T2 & FLAIR  Axials,T2  Saggitals  / Coronals.  DWI  Axials.   Clinical  details  : S/p CABG  for CAD. Evidence of multiple lacunar &  tiny sized lesions with restricted diffusion and low ADC  values are hyperintense on FLAIR images noted in both cerebellar hemispheres, occipital  lobes and parietooccipital regions (including right side of splenium of corpus callosum),  left posterior periv entricular white matter, left posterior temporal lobe, left frontal corona  radiata\n",
      "💡 Result 2: IP0000111111 067Y M T1, T2 & FLAIR  Axials,T2  Saggitals  / Coronals.  DWI  Axials.   Clinical  details  : S/p CABG  for CAD. Evidence of multiple lacunar &  tiny sized lesions with restricted diffusion and low ADC  values are hyperintense on FLAIR images noted in both cerebellar hemispheres, occipital  lobes and parietooccipital regions (including right side of splenium of corpus callosum),  left posterior periv entricular white matter, left posterior temporal lobe, left frontal corona  radiata\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define a list of test queries to be processed\n",
    "queries = [\"Patient is not cooperative\",\"including right side of splenium of corpus callosum\"]\n",
    "k = 2\n",
    "retrieve_queries(queries, k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
